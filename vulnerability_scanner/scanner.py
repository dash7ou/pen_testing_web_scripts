# !/usr/bin/env python

import requests
import re
import urlparse


class Scanner:
    def __init__(self, url, ignore_urls):
        self.target_url = url
        self.target_links = []
        self.session = requests.Session()
        self.ignore_urls = ignore_urls

    def get_links_from_url(self, target_url):
        response = self.session.get(target_url)
        return re.findall('(?:href=")(.*?)"', response.content)

    def crawl(self, url=None):
        if url == None:
            url = self.target_url

        href_links = self.get_links_from_url(url)

        for link in href_links:
            link = urlparse.urljoin(url, link)

            if '#' in link:
                link = link.split("#")[0]

            if self.target_url in link and link not in self.target_links and link not in self.ignore_urls:
                self.target_links.append(link)
                print(link)
                self.crawl(link)
